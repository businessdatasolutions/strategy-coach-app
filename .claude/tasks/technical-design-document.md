Of course. Here is the complete, final version of the Technical Design Document, incorporating all the requested details into a single, comprehensive guide.

---

# **Technical Design Document: AI Strategic Co-pilot**

## 1. Introduction

**Purpose:** This document provides a detailed technical blueprint for building the AI Strategic Co-pilot. It is intended for a junior software developer and will serve as a guide for implementation, referencing the concepts outlined in the project's Product Requirements Document (PRD).

**Core Technology Stack:**
*   **Backend Framework:** Python with FastAPI for serving the API.
*   **Orchestration:** LangChain's **LangGraph** library to manage the multi-agent workflow and state.
*   **LLMs:** LangChain integrations for various models (OpenAI, Mistral, Anthropic, etc.) to power the agents.
*   **State Persistence:** A simple file-based approach using a `strategy_map.json` file for each user session.

## 2. Core Architectural Concepts

This system is designed as an **Orchestrator-Worker** model, which is a perfect fit for LangGraph.

*   **The Graph as Orchestrator:** The `StateGraph` object from LangGraph will be our central **Orchestrator**. It doesn't make decisions itself but directs the flow of data between different processing units (nodes).
*   **Agents as Workers (Nodes):** Each "Specialist Agent" from the PRD (WHY Agent, Analogy Agent, etc.) will be implemented as a **Node** in the graph. A node is simply a Python function or a LangChain `Runnable` that performs a specific task.
*   **Centralized, Explicit State:** The entire application will revolve around a single, explicitly defined state object (`AgentState`). At every step, the graph knows the complete state of the conversation. This makes the logic predictable and easier to debug.
*   **The Socratic Loop:** The core user interaction is a loop. The graph is designed to continuously execute this loop until the strategy is complete:
    1.  Wait for user input.
    2.  Update the persistent strategy map.
    3.  Route to the appropriate specialist agent.
    4.  Generate a Socratic, guiding response.
    5.  Present the response to the user.

## 3. Detailed System Architecture

### 3.1. Project Structure

A well-organized project structure is key. Here is the recommended layout:

```
/ai-strategic-copilot
|
├── api/
│   ├── main.py             # FastAPI application entry point
│   ├── models.py           # Pydantic models for API requests/responses
│
├── core/
│   ├── graph.py            # LangGraph StateGraph definition and compilation
│   ├── router.py           # The conditional routing logic for the graph
│   ├── state.py            # Definition of the AgentState TypedDict
│
├── agents/
│   ├── __init__.py
│   ├── strategy_map_agent.py # The special agent for state persistence
│   ├── why_agent.py          # Implementation of the WHY Agent
│   ├── analogy_agent.py      # Implementation of the Analogy Agent
│   ├── logic_agent.py        # ... and so on for other agents
│
├── tools/
│   ├── __init__.py
│   ├── quiz_form_tool.py     # Example tool for gathering structured input
│
├── sessions/                 # Directory to store session-specific JSON files
│   ├── session_id_1_strategy_map.json
│   └── session_id_2_strategy_map.json
│
├── .env                      # Environment variables (API keys, etc.)
├── requirements.txt
└── README.md
```

### 3.2. State Definition (`core/state.py`)

The state is the lifeblood of our LangGraph application. It's what gets passed between every node. We will define it using Python's `TypedDict` for clarity and type safety.

```python
# core/state.py
from typing import List, TypedDict, Optional, Literal
from langchain_core.messages import BaseMessage

# Define the phases of the user journey from the PRD
JourneyPhase = Literal["WHY", "HOW", "WHAT", "COMPLETE"]

class AgentState(TypedDict):
    """
    The central state of our application. It is passed between all nodes in the graph.
    """
    # The running history of the conversation
    conversation_history: List[BaseMessage]
    
    # Path to the session's strategy_map.json file, as per the PRD
    strategy_map_path: str
    
    # The current phase of the strategic journey
    current_phase: JourneyPhase
    
    # The output from the last specialist agent that ran.
    agent_output: Optional[dict]
    
    # The final, user-facing response generated by the synthesizer
    user_response: str
```

### 3.3. The LangGraph Orchestrator (`core/graph.py`)

This is the heart of the system where we define the workflow from PRD section 4.1. The conceptual flow is:

`Entry Point` -> `Strategy Map Updater` -> `Router` -> (Conditional) `Specialist Agent` -> `END` (of one loop)

```python
# core/graph.py
from langgraph.graph import StateGraph, END
from .state import AgentState
from .router import router_node

# Import your agent functions
from agents.strategy_map_agent import strategy_map_node
from agents.why_agent import why_agent_node
from agents.analogy_agent import analogy_agent_node
# ... import other agents

def create_graph():
    """
    Builds the LangGraph StateGraph that orchestrates the conversation.
    """
    workflow = StateGraph(AgentState)

    # 1. Add Nodes
    workflow.add_node("strategy_map_updater", strategy_map_node)
    workflow.add_node("why_agent", why_agent_node)
    workflow.add_node("analogy_agent", analogy_agent_node)
    # ... add other specialist agent nodes ...

    # 2. Define the Entry Point
    workflow.set_entry_point("strategy_map_updater")

    # 3. Add Conditional Edges for Routing
    workflow.add_conditional_edges(
        "strategy_map_updater",
        router_node,
        {
            "WHY": "why_agent",
            "HOW": "analogy_agent",
            "WHAT": "strategy_map_agent", # Example: "WHAT" phase is handled by the map agent directly
            "COMPLETE": "open_strategy_agent",
            "END": END
        }
    )

    # 4. Define Loop-back Edges
    # After a specialist agent runs, the loop concludes for this turn.
    workflow.add_edge("why_agent", END)
    workflow.add_edge("analogy_agent", END)
    # ... add edges from all other specialists to END ...

    # 5. Compile the Graph
    app = workflow.compile()
    return app
```

### 3.4. The Router (`core/router.py`)

The router's only job is to look at the current state and decide which specialist agent should run next. It reads the `current_phase` which is set by the `strategy_map_node`.

```python
# core/router.py
from .state import AgentState

def router_node(state: AgentState) -> str:
    """
    Determines the next node to execute based on the current conversation phase.
    """
    phase = state["current_phase"]
    
    if phase == "WHY":
        return "WHY"
    elif phase == "HOW":
        return "HOW"
    elif phase == "WHAT":
        return "WHAT"
    elif phase == "COMPLETE":
        return "COMPLETE"
    else:
        return "END"
```

## 4. Agent Implementation Principles

Each agent is a Python function that takes the `AgentState` as input and returns a dictionary that updates the state. The `Strategy Map Agent` is a special case as it also handles all file I/O and state calculations.

### 4.1. Strategy Map Agent (The State Manager)

This is the most important agent. It updates the JSON file, calculates progress, and determines the current phase of the journey. This node runs at the start of every single turn.

```python
# agents/strategy_map_agent.py
import json
from datetime import datetime
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from core.state import AgentState

llm = ChatOpenAI(model="gpt-4o")

PROMPT_TEMPLATE = """
You are an expert strategy analyst. Your task is to update a strategy map in JSON format
based on the latest user message in a conversation. Analyze the conversation history,
especially the last message from the user. Identify any new information that maps to the
components of a business strategy. Provide a JSON object containing ONLY the fields that
need to be added or updated. Do NOT repeat existing information. If no new strategic
information is present, return an empty JSON object {{}}.

Current Strategy Map:
{strategy_map}

Conversation History:
{conversation_history}

Update JSON:
"""

def strategy_map_node(state: AgentState) -> dict:
    map_path = state['strategy_map_path']
    history = state['conversation_history']

    try:
        with open(map_path, 'r') as f:
            strategy_map = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        strategy_map = {}

    if history: # Only run LLM if there's a new message
        prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
        chain = prompt | llm
        response = chain.invoke({
            "strategy_map": json.dumps(strategy_map, indent=2),
            "conversation_history": "\n".join([f"{msg.type}: {msg.content}" for msg in history]),
        })
        updated_fields = json.loads(response.content)
        strategy_map.update(updated_fields)

    # After any potential updates, run progress calculation and save
    strategy_map = _update_metadata_and_progress(strategy_map)
    
    with open(map_path, 'w') as f:
        json.dump(strategy_map, f, indent=2)

    return {"current_phase": strategy_map.get("metadata", {}).get("current_phase", "WHY")}

def _update_metadata_and_progress(strategy_map: dict) -> dict:
    # (Implementation for progress calculation and phase transition as detailed in Section 5.2)
    # ...
    return strategy_map
```

## 5. Detailed Implementation of Key PRD Elements

This section details the specific, high-value components from the PRD that make the system unique.

### 5.1. The Strategy Map: Schema and State Persistence

The final output, `strategy_map.json`, is the single source of truth. Its schema must directly reflect the PRD's frameworks.

**Proposed JSON Schema (`sessions/{session_id}_strategy_map.json`):**

```json
{
  "metadata": {
    "sessionId": "uuid-goes-here",
    "createdAt": "iso-timestamp",
    "lastUpdatedAt": "iso-timestamp",
    "completeness": {
      "overall": 0.0,
      "stakeholder_customer": 0.0,
      "internal_process": 0.0,
      "learning_growth": 0.0,
      "value_creation": 0.0
    },
    "current_phase": "WHY"
  },
  "strategy_title": "Untitled Strategy",
  "core_purpose": {
    "why_statement": null,
    "how_actions": [],
    "what_proofs": []
  },
  "perspectives": {
    "stakeholder_customer": {
      "problem_solved": null,
      "value_proposition": null,
      "key_stakeholders": []
    },
    "internal_process": {
      "critical_processes": [],
      "current_analogy_exercise": {
        "target_company": null,
        "source_company": null,
        "desired_conclusion": null,
        "positive_analogies": [],
        "negative_analogies": [],
        "causal_theory": null
      }
    },
    "learning_growth": {
      "human_capital": [],
      "information_capital": [],
      "organization_capital": []
    },
    "value_creation": {
      "financial_value": { "objective": null, "impact": "increase|decrease|transform" },
      "manufactured_value": { "objective": null, "impact": "increase|decrease|transform" },
      "intellectual_value": { "objective": null, "impact": "increase|decrease|transform" },
      "human_value": { "objective": null, "impact": "increase|decrease|transform" },
      "social_relationship_value": { "objective": null, "impact": "increase|decrease|transform" },
      "natural_value": { "objective": null, "impact": "increase|decrease|transform" }
    }
  },
  "open_strategy_plan": null
}
```

### 5.2. Progress Tracking and Phase Transition Logic

This logic belongs inside a helper function called by `strategy_map_node` on every turn. It provides the core progress feedback loop required by the PRD.

**Location:** `agents/strategy_map_agent.py`

```python
# In agents/strategy_map_agent.py
def _update_metadata_and_progress(strategy_map: dict) -> dict:
    if "metadata" not in strategy_map:
        strategy_map["metadata"] = {}
        
    def check(data, key):
        return 1.0 if data.get(key) else 0.0

    scores = {}
    # WHY Phase Completeness
    scores["stakeholder_customer"] = check(strategy_map.get("core_purpose", {}), "why_statement")
    
    # HOW Phase Completeness
    analogy_state = strategy_map.get("perspectives", {}).get("internal_process", {}).get("current_analogy_exercise", {})
    scores["internal_process"] = check(analogy_state, "causal_theory")

    # WHAT Phase Completeness (simplified)
    value_objectives = strategy_map.get("perspectives", {}).get("value_creation", {})
    scores["value_creation"] = 1.0 if any(v.get("objective") for v in value_objectives.values()) else 0.0
    
    # Placeholder for Learning & Growth
    scores["learning_growth"] = 0.0 

    # Determine Phase
    if scores["stakeholder_customer"] < 1.0:
        current_phase = "WHY"
    elif scores["internal_process"] < 1.0:
        current_phase = "HOW"
    elif scores["value_creation"] < 1.0:
        current_phase = "WHAT"
    else:
        current_phase = "COMPLETE"
        
    strategy_map["metadata"]["completeness"] = scores
    strategy_map["metadata"]["current_phase"] = current_phase
    strategy_map["metadata"]["lastUpdatedAt"] = datetime.utcnow().isoformat()
    
    return strategy_map
```

### 5.3. WHY Agent: Implementing the Sinek Workflow

The agent must be aware of its position within the Sinek workflow. It does this by inspecting the `core_purpose` section of the strategy map.

**Location:** `agents/why_agent.py`

```python
# In agents/why_agent.py
def why_agent_node(state: AgentState) -> dict:
    with open(state['strategy_map_path'], 'r') as f:
        strategy_map = json.load(f)
    
    core_purpose = strategy_map.get("core_purpose", {})
    
    if not core_purpose.get("why_statement"):
        prompt_template = "..." # Prompt to mine the past for the WHY
    elif not core_purpose.get("how_actions"):
        prompt_template = "..." # Prompt to distill the HOWs
    else:
        prompt_template = "..." # Prompt to connect to the WHATs

    # ... (Invoke LLM with the chosen prompt) ...
    return {"user_response": "Generated Socratic question goes here"}
```

### 5.4. Analogy Agent: Managing Structured Reasoning

This agent reads and writes to its dedicated state object (`current_analogy_exercise`) to guide the user through the structured reasoning process.

**Location:** `agents/analogy_agent.py`

```python
# In agents/analogy_agent.py
def analogy_agent_node(state: AgentState) -> dict:
    with open(state['strategy_map_path'], 'r') as f:
        strategy_map = json.load(f)
    
    analogy_state = strategy_map.get("perspectives", {})...["current_analogy_exercise"]
    
    if not analogy_state.get("source_company"):
        prompt_template = "..." # Prompt to get the source company
    elif not analogy_state.get("causal_theory"):
        prompt_template = "..." # CRITICAL prompt to push for vertical (causal) relations
    # ... etc.

    # ... (Invoke LLM with the chosen prompt) ...
    return {"user_response": "Generated analogical reasoning question"}
```

### 5.5. Open Strategy Agent: Generating a Structured Plan

This agent runs when the strategy is complete. Its output is a final deliverable—a structured plan—that gets saved to the map.

**Location:** `agents/open_strategy_agent.py`

```python
# In agents/open_strategy_agent.py
def open_strategy_agent_node(state: AgentState) -> dict:
    with open(state['strategy_map_path'], 'r') as f:
        strategy_map = json.load(f)
        
    final_prompt = "..." # The detailed prompt from the previous response to generate a full plan
    
    # ... (Invoke LLM) ...
    plan_markdown = llm_response.content
    user_message = f"Your strategy map is well-defined. Here is a proposed plan to validate and mobilize it:\n\n{plan_markdown}"
    
    # Update the map with the final plan
    strategy_map["open_strategy_plan"] = plan_markdown
    with open(state['strategy_map_path'], 'w') as f:
        json.dump(strategy_map, f, indent=2)

    return {"user_response": user_message}
```

## 6. Tool Integration

The PRD mentions tools. LangChain has excellent support for this.

**Step 1: Define the Tool (`tools/quiz_form_tool.py`)**

```python
# tools/quiz_form_tool.py
from langchain_core.tools import tool

@tool
def present_quiz_form(questions: list[str]) -> str:
    """
    Presents a quiz to the user. In a real application, this emits an event
    for the frontend to render a form.
    """
    return f"[TOOL_CALL: QUIZ_FORM with questions: {questions}]"
```

**Step 2: Bind the Tool to an Agent's LLM**

You would then bind this tool to the LLM used by an agent that needs it (e.g., the Logic Agent) and instruct the agent in its prompt to use the tool when appropriate.

## 7. API Layer with FastAPI (`api/main.py`)

The API exposes our LangGraph application. It manages sessions and handles conversation turns.

```python
# api/main.py
import uuid
import os
import json
from fastapi import FastAPI
from pydantic import BaseModel
from langchain_core.messages import HumanMessage, AIMessage
from core.graph import create_graph

app_runnable = create_graph()
api = FastAPI()
SESSIONS = {} # Use Redis or a DB in production

class StartRequest(BaseModel):
    user_context: dict = {}

class MessageRequest(BaseModel):
    message: str

@api.post("/conversation/start")
async def start_conversation(request: StartRequest):
    session_id = str(uuid.uuid4())
    map_path = os.path.join("sessions", f"{session_id}_strategy_map.json")
    
    # Initialize the strategy map file with metadata
    initial_map = { "metadata": { "sessionId": session_id, "createdAt": datetime.utcnow().isoformat() } }
    with open(map_path, 'w') as f:
        json.dump(initial_map, f, indent=2)

    initial_state = {
        "conversation_history": [],
        "strategy_map_path": map_path,
    }
    SESSIONS[session_id] = initial_state
    
    return {
        "session_id": session_id,
        "message": "Hello! I am your AI Strategic Co-pilot. To begin, tell me about your business."
    }

@api.post("/conversation/{session_id}/message")
async def post_message(session_id: str, request: MessageRequest):
    if session_id not in SESSIONS:
        return {"error": "Session not found"}, 404

    current_state = SESSIONS[session_id]
    current_state["conversation_history"].append(HumanMessage(content=request.message))
    
    # Invoke the LangGraph app
    final_state = app_runnable.invoke(current_state)
    
    ai_response = final_state["user_response"]
    final_state["conversation_history"].append(AIMessage(content=ai_response))
    SESSIONS[session_id] = final_state
    
    # Read the latest map to send progress to UI
    with open(final_state["strategy_map_path"], 'r') as f:
        latest_map = json.load(f)
    
    return {
        "response": ai_response,
        "current_phase": latest_map.get("metadata", {}).get("current_phase"),
        "completeness": latest_map.get("metadata", {}).get("completeness", {})
    }
```

## 8. Step-by-Step Implementation Plan for a Junior Developer

1.  **Environment Setup:** Set up a Python environment, install dependencies from `requirements.txt`, and create your `.env` file with API keys.
2.  **Build the Foundation:** Implement the project structure, define the `AgentState`, and set up the basic FastAPI endpoints.
3.  **Implement the Core Loop:** Implement the `strategy_map_node`, including the detailed `_update_metadata_and_progress` function. Implement the rule-based `router_node`. Wire them together in `core/graph.py` and connect the runnable to the API. Test that a user message correctly updates the JSON file and phase.
4.  **Add Specialist Agents Incrementally:**
    *   Start with the `why_agent_node`. Implement its conditional prompting logic. Add it to the graph and router. Test the end-to-end flow for the WHY phase.
    *   Next, implement the `analogy_agent_node` and its state-aware logic.
    *   Continue for all other agents.
5.  **Refine and Test:** Improve agent prompts to ensure they are Socratic. Enhance the completeness calculations. Write tests for key logic, especially the router and progress tracker.
6.  **Implement Tool Usage (Advanced):** Once the core flow works, implement a simple tool and bind it to an agent to explore advanced functionality.
